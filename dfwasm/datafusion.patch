diff --git a/Cargo.toml b/Cargo.toml
index ab3f427e..2f24803f 100644
--- a/Cargo.toml
+++ b/Cargo.toml
@@ -31,6 +31,47 @@ members = [
 ]
 exclude = ["datafusion-cli"]
 
+# Enable the version 2 feature resolver, which avoids unifying features for targets that are not being built
+#
+# Critically this prevents dev-dependencies from enabling features even when not building a target that
+# uses dev-dependencies, e.g. the library crate. This in turn ensures that we can catch invalid feature
+# flag combinations that would otherwise only surface in dependent crates
+#
+# Reference - https://doc.rust-lang.org/nightly/cargo/reference/features.html#feature-resolver-version-2
+#
+resolver = "2"
+
 [profile.release]
 codegen-units = 1
 lto = true
+
+[patch.crates-io]
+# https://github.com/samdenty/reqwest adds tokio features but names the package reqwest-wasm
+# https://github.com/milesforks/reqwest renames package to reqwest and bumps version
+reqwest = { version="0.11.16", git = "https://github.com/milesforks/reqwest"  }
+
+# ARROW: this git hash is ~2 commits before 26.0.0
+arrow = { git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+arrow-array = { git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+arrow-buffer ={ git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+arrow-data = { git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+arrow-flight ={ git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+arrow-schema ={ git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+arrow-select ={ git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+parquet = { git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+parquet_derive ={ git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+parquet_derive_test = {git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+object_store ={ git = "https://github.com/apache/arrow-rs", rev = "87ac05bcafd343d3d8ad3b519631d83090afeb1c" }
+
+# ARROW: uncomment these to develop from a local version of the arrow-rs repository
+# arrow = { path = "../arrow-rs/arrow" }
+# arrow-array = { path = "../arrow-rs/arrow-array" }
+# arrow-buffer = { path = "../arrow-rs/arrow-buffer" }
+# arrow-data = { path = "../arrow-rs/arrow-data" }
+# arrow-flight = { path = "../arrow-rs/arrow-flight" }
+# arrow-schema = { path = "../arrow-rs/arrow-schema" }
+# arrow-select = { path = "../arrow-rs/arrow-select" }
+# parquet = { path = "../arrow-rs/parquet" }
+# parquet_derive = { path = "../arrow-rs/parquet_derive" }
+# parquet_derive_test = { path = "../arrow-rs/parquet_derive_test" }
+# object_store = { path = "../arrow-rs/object_store" }
diff --git a/README.md b/README.md
index 29113678..4ca01a91 100644
--- a/README.md
+++ b/README.md
@@ -17,6 +17,12 @@
   under the License.
 -->
 
+# Patch
+
+```
+export RUSTFLAGS="--cfg tokio_unstable" ; cargo build --verbose --target wasm32-wasi --package datafusion --package datafusion-expr --package datafusion-proto --package datafusion-common --no-default-features --features datafusion-proto/default,datafusion/regex_expressions,datafusion/unicode_expressions,datafusion/object_store,datafusion-common/apache-avro,datafusion-common/parquet
+```
+
 # DataFusion
 
 <img src="docs/source/_static/images/DataFusion-Logo-Background-White.svg" width="256" alt="logo"/>
diff --git a/datafusion/common/Cargo.toml b/datafusion/common/Cargo.toml
index d69bc197..74c23353 100644
--- a/datafusion/common/Cargo.toml
+++ b/datafusion/common/Cargo.toml
@@ -42,7 +42,17 @@ pyarrow = ["pyo3", "arrow/pyarrow"]
 apache-avro = { version = "0.14", default-features = false, features = ["snappy"], optional = true }
 arrow = { version = "25.0.0", default-features = false }
 cranelift-module = { version = "0.89.0", optional = true }
-object_store = { version = "0.5.0", default-features = false, optional = true }
+# object_store = { version = "0.5.0", default-features = false, optional = true }
+#"ring", "reqwest/json", "reqwest/stream", "chrono/serde", "quick-xml",
+# cloud = ["serde", "serde_json", "quick-xml", "reqwest", "reqwest/json", "reqwest/stream", "chrono/serde", "base64", "rand", "ring", "getrandom"]
+# ["serde", "serde_json", "reqwest", "base64", "rand"]#
+# tokio = { version = "1.0", features = ["rt", "macros", "io-util"] }
+object_store = {version = "0.5.1", default_features = false, features = ["serde", "serde_json", "quick-xml", "reqwest", "base64", "rand"], optional = true}
+reqwest = { version = "0.11.16", features = ["json", "stream", "blocking"] }
+
+# chrono = { version = "0.4.22", features = ["serde", "wasmbind","wasm-bindgen"], default_features = true }
+
+# object_store = "0.5.0"
 ordered-float = "3.0"
 parquet = { version = "25.0.0", default-features = false, optional = true }
 pyo3 = { version = "0.17.1", optional = true }
diff --git a/datafusion/core/Cargo.toml b/datafusion/core/Cargo.toml
index 7e9be303..449366a8 100644
--- a/datafusion/core/Cargo.toml
+++ b/datafusion/core/Cargo.toml
@@ -41,7 +41,7 @@ path = "src/lib.rs"
 # Used to enable the avro format
 avro = ["apache-avro", "num-traits", "datafusion-common/avro"]
 crypto_expressions = ["datafusion-physical-expr/crypto_expressions"]
-default = ["crypto_expressions", "regex_expressions", "unicode_expressions"]
+default = ["regex_expressions", "unicode_expressions"] # -"crypto_expressions",
 # Used for testing ONLY: causes all values to hash to the same value (test for collisions)
 force_hash_collisions = []
 # Used to enable JIT code generation
@@ -54,15 +54,17 @@ simd = ["arrow/simd"]
 unicode_expressions = ["datafusion-physical-expr/regex_expressions", "datafusion-sql/unicode_expressions"]
 
 [dependencies]
-ahash = { version = "0.8", default-features = false, features = ["runtime-rng"] }
+ahash = { version = "^0.8", default-features = false, features = ["runtime-rng"] }
 apache-avro = { version = "0.14", optional = true }
 arrow = { version = "25.0.0", features = ["prettyprint"] }
-async-compression = { version = "0.3.14", features = ["bzip2", "gzip", "futures-io", "tokio"] }
+# https://github.com/Nemo157/async-compression/issues/142
+async-compression = { version = "0.3.15", features = ["gzip", "tokio", "futures-io"] } # -"bzip2", -"tokio"
 async-trait = "0.1.41"
 bytes = "1.1"
-bzip2 = "0.4.3"
+bzip2 = { version = "0.4.3", optional = true }
+# chrono = { git = "https://github.com/chronotope/chrono", version = "0.5.0-alpha.1", default-features = false, features = ["serde", "wasmbind", "wasm-bindgen"] }
 chrono = { version = "0.4.22", default-features = false }
-datafusion-common = { path = "../common", version = "13.0.0", features = ["parquet", "object_store"] }
+datafusion-common = { path = "../common", version = "13.0.0", default-features = false, features = [ "parquet", "object_store"] } #-"object_store", -py03, "apache-avro", "cranelift-module",
 datafusion-expr = { path = "../expr", version = "13.0.0" }
 datafusion-jit = { path = "../jit", version = "13.0.0", optional = true }
 datafusion-optimizer = { path = "../optimizer", version = "13.0.0" }
@@ -78,10 +80,14 @@ lazy_static = { version = "^1.4.0" }
 log = "^0.4"
 num-traits = { version = "0.2", optional = true }
 num_cpus = "1.13.0"
-object_store = "0.5.0"
+# https://github.com/apache/arrow-rs/blob/master/object_store/Cargo.toml
+# object_store = {version = "0.5.1", default_features = false, features = ["cloud"], optional = false}
+object_store = {version = "0.5.1", default_features = false, features = ["serde", "serde_json", "reqwest", "base64", "rand"], optional = true} #"ring", "reqwest/json", "reqwest/stream", "chrono/serde", "quick-xml",
 ordered-float = "3.0"
 parking_lot = "0.12"
-parquet = { version = "25.0.0", features = ["arrow", "async"] }
+# note: parquet is using version of zstd which does not compile to wasm
+# zstd = { version = "0.11.1", optional = true, default-features = false }
+parquet = { version = "25.0.0", default_features = false,  features = ["arrow", "async", "snap", "brotli", "flate2", "base64"] } # -lz4, -zstd
 paste = "^1.0"
 percent-encoding = "2.2.0"
 pin-project-lite = "^0.2.7"
@@ -91,11 +97,15 @@ rayon = { version = "1.5", optional = true }
 smallvec = { version = "1.6", features = ["union"] }
 sqlparser = "0.25"
 tempfile = "3"
-tokio = { version = "1.0", features = ["macros", "rt", "rt-multi-thread", "sync", "fs", "parking_lot"] }
-tokio-stream = "0.1"
-tokio-util = { version = "0.7.4", features = ["io"] }
+# tokio = { version = "1.0", features = ["macros", "rt", "rt-multi-thread", "sync", "fs", "parking_lot"] } # -"rt-multi-thread", -"fs", -"parking_lot"
+# TODO: rustls support ? https://github.com/samdenty/reqwest/blob/master/Cargo.toml
+tokio = { version = "1.0", features = ["rt", "macros", "io-util", "parking_lot"] }
+tokio-stream = { version = "0.1", default_features = false, features = ["time"] } #-"io_util"
+tokio-util = { version = "0.7.4", features = ["io"] }  #-"io"
 url = "2.2"
 uuid = { version = "1.0", features = ["v4"] }
+# force reqwest-wasm to resolve (via patch in our downstream consumer) so tokio::spawn_blocking can work
+reqwest = { version = "0.11.16", features = ["json", "stream", "blocking"] }
 
 [dev-dependencies]
 arrow = { version = "25.0.0", features = ["prettyprint", "dyn_cmp_dict"] }
diff --git a/datafusion/core/src/datasource/file_format/file_type.rs b/datafusion/core/src/datasource/file_format/file_type.rs
index f08a21ca..901fc851 100644
--- a/datafusion/core/src/datasource/file_format/file_type.rs
+++ b/datafusion/core/src/datasource/file_format/file_type.rs
@@ -20,9 +20,10 @@
 use crate::error::{DataFusionError, Result};
 use std::io::Error;
 
-use async_compression::tokio::bufread::{
-    BzDecoder as AsyncBzDecoder, GzipDecoder as AsyncGzDecoder,
-};
+#[cfg(feature = "dep:bzip2")]
+use async_compression::tokio::bufread::BzDecoder as AsyncBzDecoder;
+use async_compression::tokio::bufread::GzipDecoder as AsyncGzDecoder;
+#[cfg(feature = "dep:bzip2")]
 use bzip2::read::BzDecoder;
 
 use crate::datasource::file_format::avro::DEFAULT_AVRO_EXTENSION;
@@ -46,6 +47,7 @@ pub trait GetExt {
 pub enum FileCompressionType {
     /// Gzip-ed file
     GZIP,
+    #[cfg(feature = "dep:bzip2")]
     /// Bzip2-ed file
     BZIP2,
     /// Uncompressed file
@@ -56,6 +58,7 @@ impl GetExt for FileCompressionType {
     fn get_ext(&self) -> String {
         match self {
             FileCompressionType::GZIP => ".gz".to_owned(),
+            #[cfg(feature = "dep:bzip2")]
             FileCompressionType::BZIP2 => ".bz2".to_owned(),
             FileCompressionType::UNCOMPRESSED => "".to_owned(),
         }
@@ -69,6 +72,7 @@ impl FromStr for FileCompressionType {
         let s = s.to_uppercase();
         match s.as_str() {
             "GZIP" | "GZ" => Ok(FileCompressionType::GZIP),
+            #[cfg(feature = "dep:bzip2")]
             "BZIP2" | "BZ2" => Ok(FileCompressionType::BZIP2),
             "" => Ok(FileCompressionType::UNCOMPRESSED),
             _ => Err(DataFusionError::NotImplemented(format!(
@@ -104,6 +108,7 @@ impl FileCompressionType {
                 ReaderStream::new(AsyncGzDecoder::new(StreamReader::new(s)))
                     .map_err(err_converter),
             ),
+            #[cfg(feature = "dep:bzip2")]
             FileCompressionType::BZIP2 => Box::new(
                 ReaderStream::new(AsyncBzDecoder::new(StreamReader::new(s)))
                     .map_err(err_converter),
@@ -119,6 +124,7 @@ impl FileCompressionType {
     ) -> Box<dyn std::io::Read + Send> {
         match self {
             FileCompressionType::GZIP => Box::new(GzDecoder::new(r)),
+            #[cfg(feature = "dep:bzip2")]
             FileCompressionType::BZIP2 => Box::new(BzDecoder::new(r)),
             FileCompressionType::UNCOMPRESSED => Box::new(r),
         }
diff --git a/datafusion/core/src/datasource/listing/table.rs b/datafusion/core/src/datasource/listing/table.rs
index deaa0924..d07e40a7 100644
--- a/datafusion/core/src/datasource/listing/table.rs
+++ b/datafusion/core/src/datasource/listing/table.rs
@@ -17,7 +17,8 @@
 
 //! The table implementation.
 
-use ahash::HashMap;
+// use ahash::HashMap;
+use std::collections::HashMap;
 use std::str::FromStr;
 use std::{any::Any, sync::Arc};
 
diff --git a/datafusion/core/src/datasource/object_store.rs b/datafusion/core/src/datasource/object_store.rs
index 69b18313..dede0581 100644
--- a/datafusion/core/src/datasource/object_store.rs
+++ b/datafusion/core/src/datasource/object_store.rs
@@ -20,7 +20,7 @@
 //! and query data inside these systems.
 
 use datafusion_common::{DataFusionError, Result};
-use object_store::local::LocalFileSystem;
+// use object_store::memory::InMemory;
 use object_store::ObjectStore;
 use parking_lot::RwLock;
 use std::collections::HashMap;
@@ -161,8 +161,8 @@ impl ObjectStoreRegistry {
     /// may be explicity registered with calls to [`ObjectStoreRegistry::register_store`] or
     /// created lazily, on-demand by the provided [`ObjectStoreProvider`]
     pub fn new_with_provider(provider: Option<Arc<dyn ObjectStoreProvider>>) -> Self {
-        let mut map: HashMap<String, Arc<dyn ObjectStore>> = HashMap::new();
-        map.insert("file://".to_string(), Arc::new(LocalFileSystem::new()));
+        let map: HashMap<String, Arc<dyn ObjectStore>> = HashMap::new();
+        // map.insert("file://".to_string(), Arc::new(InMemory::new()));
         Self {
             object_stores: RwLock::new(map),
             provider,
@@ -267,7 +267,6 @@ mod tests {
         let url = ListingTableUrl::parse("hdfs://localhost:8020/key").unwrap();
         sut.get_by_url(&url).unwrap();
     }
-
     #[test]
     fn test_get_by_url_s3() {
         let sut = ObjectStoreRegistry::default();
@@ -275,7 +274,6 @@ mod tests {
         let url = ListingTableUrl::parse("s3://bucket/key").unwrap();
         sut.get_by_url(&url).unwrap();
     }
-
     #[test]
     fn test_get_by_url_file() {
         let sut = ObjectStoreRegistry::default();
diff --git a/datafusion/core/src/physical_plan/sorts/sort.rs b/datafusion/core/src/physical_plan/sorts/sort.rs
index 763c7c55..04a0faac 100644
--- a/datafusion/core/src/physical_plan/sorts/sort.rs
+++ b/datafusion/core/src/physical_plan/sorts/sort.rs
@@ -598,7 +598,8 @@ async fn spill_partial_sorted_stream(
 ) -> Result<()> {
     let (sender, receiver) = tokio::sync::mpsc::channel(2);
     let path: PathBuf = path.into();
-    let handle = task::spawn_blocking(move || write_sorted(receiver, path, schema));
+
+    let handle = task::spawn(async move { write_sorted(receiver, path, schema) });
     while let Some(item) = in_mem_stream.next().await {
         sender.send(item).await.ok();
     }
@@ -620,11 +621,22 @@ fn read_spill_as_stream(
         Sender<ArrowResult<RecordBatch>>,
         Receiver<ArrowResult<RecordBatch>>,
     ) = tokio::sync::mpsc::channel(2);
-    let join_handle = task::spawn_blocking(move || {
+    let join_handle = task::spawn(async move {
         if let Err(e) = read_spill(sender, path.path()) {
             error!("Failure while reading spill file: {:?}. Error: {}", path, e);
         }
     });
+    // let join_handle = task::spawn(move || {
+    //     debug!("Creating fake join_handle for wasm without spawn_blocking support")
+    // });
+
+    // block on the main thread for wasm
+    // move || {
+    //     if let Err(e) = read_spill(sender, path.path()) {
+    //         error!("Failure while reading spill file: {:?}. Error: {}", path, e);
+    //     }
+    // }();
+
     Ok(RecordBatchReceiverStream::create(
         &schema,
         receiver,
diff --git a/datafusion/core/src/test/mod.rs b/datafusion/core/src/test/mod.rs
index bce27767..60738f85 100644
--- a/datafusion/core/src/test/mod.rs
+++ b/datafusion/core/src/test/mod.rs
@@ -33,7 +33,9 @@ use array::ArrayRef;
 use arrow::array::{self, Array, Decimal128Builder, Int32Array};
 use arrow::datatypes::{DataType, Field, Schema, SchemaRef};
 use arrow::record_batch::RecordBatch;
+#[cfg(feature = "dep:bzip2")]
 use bzip2::write::BzEncoder;
+#[cfg(feature = "dep:bzip2")]
 use bzip2::Compression as BzCompression;
 use flate2::write::GzEncoder;
 use flate2::Compression as GzCompression;
@@ -115,6 +117,7 @@ pub fn partitioned_file_groups(
             FileCompressionType::GZIP => {
                 Box::new(GzEncoder::new(file, GzCompression::default()))
             }
+            #[cfg(feature = "dep:bzip2")]
             FileCompressionType::BZIP2 => {
                 Box::new(BzEncoder::new(file, BzCompression::default()))
             }
diff --git a/datafusion/optimizer/Cargo.toml b/datafusion/optimizer/Cargo.toml
index 729e2306..90445850 100644
--- a/datafusion/optimizer/Cargo.toml
+++ b/datafusion/optimizer/Cargo.toml
@@ -39,6 +39,7 @@ unicode_expressions = []
 [dependencies]
 arrow = { version = "25.0.0", features = ["prettyprint"] }
 async-trait = "0.1.41"
+# chrono = { git = "https://github.com/chronotope/chrono", version = "0.5.0-alpha.1", default-features = false }
 chrono = { version = "0.4.22", default-features = false }
 datafusion-common = { path = "../common", version = "13.0.0" }
 datafusion-expr = { path = "../expr", version = "13.0.0" }
diff --git a/datafusion/physical-expr/Cargo.toml b/datafusion/physical-expr/Cargo.toml
index e0703829..832ef2e8 100644
--- a/datafusion/physical-expr/Cargo.toml
+++ b/datafusion/physical-expr/Cargo.toml
@@ -43,7 +43,8 @@ ahash = { version = "0.8", default-features = false, features = ["runtime-rng"]
 arrow = { version = "25.0.0", features = ["prettyprint"] }
 blake2 = { version = "^0.10.2", optional = true }
 blake3 = { version = "1.0", optional = true }
-chrono = { version = "0.4.22", default-features = false }
+# chrono = { git = "https://github.com/chronotope/chrono", version = "0.5.0-alpha.1", default-features = true, features = ["wasmbind", "wasm-bindgen"] }
+chrono = { version = "0.4.22" }
 datafusion-common = { path = "../common", version = "13.0.0" }
 datafusion-expr = { path = "../expr", version = "13.0.0" }
 datafusion-row = { path = "../row", version = "13.0.0" }
diff --git a/datafusion/physical-expr/src/datetime_expressions.rs b/datafusion/physical-expr/src/datetime_expressions.rs
index 0214d1bf..0b37a5cc 100644
--- a/datafusion/physical-expr/src/datetime_expressions.rs
+++ b/datafusion/physical-expr/src/datetime_expressions.rs
@@ -189,7 +189,8 @@ fn quarter_month(date: &NaiveDateTime) -> u32 {
 }
 
 fn date_trunc_single(granularity: &str, value: i64) -> Result<i64> {
-    let value = timestamp_ns_to_datetime(value).with_nanosecond(0);
+    // timestamp_ns_to_datetime now returns Option (https://github.com/apache/arrow-rs/pull/2894/files)
+    let value = timestamp_ns_to_datetime(value).unwrap().with_nanosecond(0);
     let value = match granularity {
         "second" => value,
         "minute" => value.and_then(|d| d.with_second(0)),
